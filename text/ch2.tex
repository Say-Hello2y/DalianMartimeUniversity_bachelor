\section{无人驾驶决策和CARLA仿真环境}

\subsection{无人驾驶技术模块概述}
无人 驾 驶经典结构由 感知 、 决 策、
控 制 三大 功能构成  。 不同的传感器和算法又组成了各种各样的子功能模块，一起构成了上述几大功能。

\subsubsection{环境感知}
环境感知作为第一环节，涵盖了定 位 、 检 测 、 目标预测。定位功 能 又可被划分为全 局定位与局部定位。全 局定 位可以凭借GPS定 位或我国的北斗导航系统来完成 ， 凭此得到无人车坐标，但是一旦车辆在复 杂 的 环境条件下 
 ， 上述方法定位准确性就会大幅下降 ， 此时就 需要云端地 图的帮助。 智 能 车利用车 载 的 激 光 雷 达、车载 摄像机、
 各种毫米 波 雷 达来探查周边环境 ， 与云端地图相匹配 ， 在高清地图中确认车辆位置
 。近年来，随着深度学习算法和传统视觉处理算法的结合，仅使用视觉的环境感知模块发展迅速。
 检 测模块一般涵盖终点检测、 路人、  减速牌等环境信息的检测等。我们根据 检测物的状态是否会随时间变化，可将检测划分为静态检测和动态检测。 静态检测通常来说可
以通过自身传感器 和云端数据合作来实现 ，如识别出限速标志，障碍物等。动态检测则麻烦的多 ，因为其状态会随时间改变 ， 所 以检测过程
使用了检测( Detection)-分类(Classification)-追踪(Tracking)-分割(Segmentation) 的拓扑结构 。检测 模块通常采取特定的神经网络；
 分类和追踪模块则一般采取先进的神经网络； 分割模块对输入图像进行语义分割，实现了无人车辆对所驾驶环境的感知
 ，其实现通常使用全卷积网络。
  预测功能可由两种途径完成，一种途径为使用规则，另一种途径为使用数据。使用规则 的 预测是指设计者事先对行车环境做了一定限制，即对各种现实行车环境模型
  进行建模，无人车根据这些模型输出对目标的预测
  ，由于不 可 能 枚举 所有 的行车环境，所以这种策略往往 十分脆弱 。 使用数据 的预 测一般是指
   利用前沿学科的一些方法 
  ， 如使用 神经网络或其他方法得到的预 训练模 型 对周围障碍物或车道线进行预测 ，其实现目前一般采用 循环卷 积 神经 网络加上激光雷达
  分别做车道线和障碍物预测，预测结果也是两者结合的产物。
\subsubsection{行为决策}
决策 模块毫无疑问是 无 人 驾 驶车 辆的核心 ， 其研究的难点在于如何在各种不确 定 的  、强耦合的 环境中 ， 让 无 人
车 做 出 正 确 的 决 策  。 决策需要在不确定因素的干扰下，安全的完成任务，因此大多数决策模块采取的都是防御的策略，来确保无人车的安全。
决 策 模块大体上实现的就是路径规划的功能。

路径规划可以分为长期路径决策和局部路径决策，长期路径规划常使用迪杰斯科特或者A*算法，局部路径决策比较复杂
，需要根据感知模块的输入如交通标志的信息（比如红绿灯、车道线、限速标志等）、障碍物信息、道路结构信息等
来输出相应的动作决策和限制信息。传统的方法大都是基于规则的方法，通过对可能遇到的各种情况的枚举，输出相应
的决策，这种决策系统一旦遇到规则所没有涉及到的情况，无人车的安全性就会下降。
\subsubsection{运动控制}
运动控制模块依照决策系统的输出，再依据车辆的动力学模型 对速度指令进行滤波，将滤波后的速度指令发送到 中 心
控制 计 算机，由中心控制计算机发出具体驾驶指令， 使车辆尽 可能 的按照规定的速度与路线行驶 到目的地。

目前无人 车的运动控制有三种 方案 ： 分别是PID（Proportional Integral Derivative）、 
LQR（Linear Quadratic Regulator）和
MPC（Model Predictice Control）
 。MPC控制 器突出节能特点。PID控制突出适用范围广。
LQR最优控制可以用较低的成本达到较好的控制效果。


\subsection{CARLA仿真环境}
\subsubsection{CARLA简介}
CARLA是由英特尔实验室 ， 丰田研究所， UBA的计算机视觉中心研究所联合开发使用的开源免费无 人 驾 驶 仿 真平台，一经出现就因为其开源特点得到了大量支持，如今已是无人驾驶领域第一开源平台。

CARLA有很多优点，第
一个 优点是是其可以让使用者自行配置天气条件，以模拟在不同环境下的汽车的安全行驶问题，节约实际测试成本。
除此之外，开 发者也能自定义属于自己的地 图 。

CARLA第 二个优点是内置大量传感器， 例如深度、普通RGB与语义相机以及毫米波雷达等
， 并开放了PythonAPI以供使用者配置传感器属性。

CARLA第 三 个优点是其支持同步训练，即使用者可以再一个Carla环境中训练多个智能体，这个特点减少了使用者同时训练多个智能体的成本，同时也真实的模拟了实际无人驾驶情况 。 此外，CARLA
开发了ROS-bridge模块，以便于人们同时使用ROS系 统 。

CARLA也给使用者提供了无人驾驶决策的三个模板，分别是 ： module-perception control pipeline（模型感知控制）; end-to-end imitation learning（端到端的模仿学习）, end-to-end reinforcement learning（端到端的强化学习）。 其中 ，模型感知的成 绩最好， 其 次 是 模仿学习
，强化学习排最 后 。 使用者可 以 参照这三个模板开发自己的程序。
\subsubsection{CARLA中的传感器}

在本文中主要使用了，CARLA传感器中的Semantic segmentation camera（语义分割相机），Collision detector（碰撞检测），Lane invasion detector（车道入侵检测），RGB camera（RGB相机）
故只对上述传感器进行介绍。
Semantic segmentation camera即语义相机，该摄像机通过内置的标签以不同的颜色显示物体来对可见的每个物体进行分类（例如，行人与车辆）。 
当模拟开始时，场景中的每个元素都会创建一个标签。
该相机输出的图像为R通道值为标签信息的图像：即R值为x的像素属于带有标签x的对象。具体标签信息，如表~\ref{tab:tab2}所示，在本文中为了简化训练难度，将语义相机的标签信息做了重新定义以减少训练时间。
\makeatletter% Set distance from top of page to first float
\setlength{\@fptop}{5pt}
\makeatother

\begin{table}[H]
  \centering
  \caption{\textbf{CARLA语义分割标签}}
  \begin{tabular}{lll}
    \toprule
    Value          &       Tag & 本文所用标签              \\
    \midrule
    0   & - & -\\ 
    1   & 建筑物& 行人                     \\
    2 & 栅栏& 行人    \\
    3 & 其他 & 行人 \\
    4 & 行人   & 行人     \\
    5 & 杆状物   & 其他    \\
    6 & 车道线      & 栅栏  \\
    7 & 公路    & 建筑物  \\
    8 & 人行道    & 行人    \\
    9 & 蔬菜     & 行人   \\
    10 & 车辆  & 杆状物     \\
    11& 墙    & 行人  \\
    12 & 交通标志   & 行人    \\
    \bottomrule
  \end{tabular}
  \label{tab:tab2}
\end{table}

Collision detector（碰撞检测）传感器每次在其parent actor与仿真环境中的任何事物发生碰撞时都会记录一个事件。 在单个模拟步骤中可能会检测到多个碰撞。 
为了确保检测到与任何种类的对象的冲突，服务器会为建筑物或灌木丛等元素创建"fake" actors，以便可以检索语义标签以对其进行标识。

Lane invasion detector（车道入侵检测）每次其 parent actor 超过车道标记时，都会注册一个事件。 
传感器使用地图的OPENDRIVE描述所提供的道路数据，通过考虑车轮之间的空间来确定 parent actor是否正在侵入另一个车道。

RGB camera（RGB相机）RGB摄像机充当常规摄像机，用于捕获场景中的图像。
\subsubsection{CARLA的使用}
Actors是Carla的一个核心概念，在Carla中人工创建的物体都称为Actors（演员），包括：车辆，行人，传感器等等。
而创建Actor，我们需要提供想要创建的Actor的类型，不同的类型会有不同的属性，比如一台车，它可以是不同的型号，可以是不同的颜色或外观，车辆类的actor可以通过油门和方向盘来控制，
而如果actor是一个传感器，我们需要提供传感器的类型，在车中的位置transform，也就是类似于需要使用一个模板，其在Carla中被称为蓝图，
即Blueprints，Carla中已经内置了一个蓝图库，里边包含了许多不同的Actors。

Calra的使用可以简单理解为客户端和PYTHONAPI的交互，开发者通过官方提供的PYTHONAPI样例，学习如何产生与控制actor。具体使用过程中，Carla是以python中库的
形式出现的，即只需要import carla 就可以使用python程序与Carla客户端进行交互。
Carla这种特点使得开发人员可以很方便的在Carla上验证自己的无人驾驶控制算法。

\subsection{本章小结}
本章介绍了无人驾驶系统的基本组成，通过介绍，阐述了决策模块的基本结构。
此外对本文所用的CARLA仿真环境进行了介绍，其中详细介绍了本文主要使用的传感器，并简要介绍了Calra如何使用。
